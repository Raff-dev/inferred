{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the time range\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-12-31'\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Define the patterns for each data stream using a dictionary of lambda functions\n",
    "sensors = [\n",
    "    lambda data: np.cumsum(data),\n",
    "    lambda data: np.sin(2 * np.pi * (date_range.dayofyear - 1) / 365),\n",
    "    lambda data: 0.1 * np.cumsum(data) + np.linspace(0, 1, len(date_range)),\n",
    "    lambda data: np.array([np.random.randn()] + [0.9 * data[j-1] + np.random.randn() for j in range(1, len(date_range))]),\n",
    "    lambda data: np.array([np.random.randn()] + [np.random.randn() + 0.5 * data[j-1] for j in range(1, len(date_range))]),\n",
    "    lambda data: 0.1 * np.cumsum(data) + np.sin(2 * np.pi * date_range.dayofyear / 365),\n",
    "    lambda data: np.array([100 if j == 0 else data[j-1] * np.exp((0.1 - 0.5 * 0.2**2) * 1/365 + 0.2 * np.sqrt(1/365) * np.random.randn()) for j in range(len(date_range))]),\n",
    "    lambda data: np.random.poisson(1, size=len(date_range)),\n",
    "    lambda data: np.random.binomial(1, 0.5, size=len(date_range))\n",
    "]\n",
    "\n",
    "# Generate 10 random data streams using the lambda functions\n",
    "data = np.random.randn(len(date_range), 10)\n",
    "for s, sensor in enumerate(sensors):\n",
    "    data[:, s] = sensor(data[:, s])\n",
    "\n",
    "# Convert the data to a Pandas DataFrame\n",
    "df = pd.DataFrame(data, index=date_range, columns=[f'dimension_{i}' for i in range(1, 11)])\n",
    "\n",
    "# Plot the data\n",
    "df.plot(subplots=True, figsize=(10, 20), color=\"r\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NOISE_MAGNITUDE = 0.1\n",
    "\n",
    "# Define the time range\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-12-31'\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "og_func = lambda data: np.array([np.random.randn()] + [np.random.randn() + 0.5 * data[j-1] for j in range(1, len(date_range))])\n",
    "\n",
    "data = og_func(np.zeros(len(date_range)))\n",
    "noise = np.cumsum(np.random.randn(len(data)))\n",
    "prediction = data + NOISE_MAGNITUDE * noise\n",
    "\n",
    "# # Convert the data to a Pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'original': data,\n",
    "    'digital_twin': prediction\n",
    "    },\n",
    "    index=date_range\n",
    ")\n",
    "\n",
    "# Plot the data\n",
    "df.plot(figsize=(10, 6))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NOISE_MAGNITUDE = 0.2\n",
    "\n",
    "# Define the time range with a one-day interval in seconds\n",
    "start_date = '2022-01-01 00:00:00'\n",
    "end_date = '2022-01-01 00:30:00'\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='S')\n",
    "num_samples = len(date_range)\n",
    "\n",
    "sensors = [    \n",
    "    lambda data: (np.arange(num_samples) % (24*60)) / (24*60),\n",
    "    lambda data: (np.arange(num_samples) % (12*60) >= (12*60)/2).astype(float),\n",
    "    lambda data: 0.5 * np.sin(2 * np.pi * np.arange(num_samples) / (6*60)) + 0.5,\n",
    "    lambda data: np.cumsum(data),\n",
    "    lambda data: np.array([0.9 * data[j] + np.random.randn() for j in range(num_samples)]),\n",
    "    lambda data: np.array([0.5 * data[j] + np.random.randn() for j in range(num_samples)]),\n",
    "    lambda data: np.array([data[j] * np.exp((0.1 - 0.5 * 0.2**2) * 1/365 + 0.2 * np.sqrt(1/365) * np.random.randn()) for j in range(num_samples)]),\n",
    "    lambda data: 0.1 * np.cumsum(data) + np.linspace(0, 1, num_samples),\n",
    "    lambda data: 0.1 * np.cumsum(data) + np.sin(2 * np.pi * date_range.dayofyear / 365),\n",
    "    lambda data: np.random.poisson(1),\n",
    "    lambda data: np.random.binomial(100, 0.5),\n",
    "]\n",
    "\n",
    "# Generate 10 random data streams using the lambda functions\n",
    "data = np.random.randn(len(date_range), len(sensors))\n",
    "for s, sensor in enumerate(sensors):\n",
    "    data[:, s] = sensor(data[:, s])\n",
    "\n",
    "# Plot the data and their noise for each function\n",
    "for s in range(len(sensors)):\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    original_data = data[:, s]\n",
    "    \n",
    "    noise = np.cumsum(np.random.randn(len(original_data)))\n",
    "    ratio = np.max(np.abs(original_data)) / np.max(np.abs(noise))\n",
    "    prediction = original_data + NOISE_MAGNITUDE * noise * ratio\n",
    "    \n",
    "    plt.plot(date_range, original_data, label='original')\n",
    "    plt.plot(date_range, prediction, label='noisy')\n",
    "    plt.title(f'Sensor {s+1}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'inferred-backend-Qq-bezCg-py3.10' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/raff/.cache/pypoetry/virtualenvs/inferred-backend-Qq-bezCg-py3.10/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Constants\n",
    "NOISE_MAGNITUDE = 0.2\n",
    "API_URL = 'http://localhost:8000/api'\n",
    "API_TICK = f\"{API_URL}/tick\"\n",
    "API_PREDICTION = f\"{API_URL}/prediction\"\n",
    "\n",
    "# Define the time range with a one-day interval in seconds\n",
    "LOOKAHEAD = 100\n",
    "\n",
    "sensors = [\n",
    "    lambda seed, date: (np.arange(1) % (24*60)) / (24*60),\n",
    "    lambda seed, date: (np.arange(1) % (12*60) >= (12*60)/2).astype(float),\n",
    "    lambda seed, date: 0.5 * np.sin(2 * np.pi * np.arange(1) / (6*60)) + 0.5,\n",
    "    lambda seed, date: 0.9 * seed + NOISE_MAGNITUDE * np.random.randn(),\n",
    "    lambda seed, date: np.random.randn() + 0.5 * seed,\n",
    "    lambda seed, date: seed * np.exp((0.1 - 0.5 * 0.2**2) * 1/365 + 0.2 * np.sqrt(1/365) * np.random.randn()),\n",
    "    lambda seed, date: 0.1 * seed + np.sin(2 * np.pi * date.second / 60),\n",
    "    lambda seed, date: 0.1 * seed + np.linspace(0, 1, 1),\n",
    "    lambda seed, date: np.random.poisson(1, size=1),\n",
    "    lambda seed, date: np.random.binomial(4, 0.5, size=1),\n",
    "]\n",
    "\n",
    "def real_time_date(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "    current_time = start_time\n",
    "    while True:\n",
    "        yield current_time\n",
    "        current_time += timedelta(seconds=1)\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "def generate_data():\n",
    "    data_seed = np.random.randn(LOOKAHEAD, len(sensors))\n",
    "    sensor_data = np.zeros(LOOKAHEAD, len(sensors))\n",
    "    start_time = datetime.now()\n",
    "    current_time = start_time\n",
    "    \n",
    "    # initialize the data, so we can mock predictions\n",
    "    for s, sensor in enumerate(sensors):\n",
    "        for i in range(LOOKAHEAD):\n",
    "            sensor_data[i, s] = sensor(data_seed[i, s], current_time)\n",
    "            current_time += timedelta(seconds=1)\n",
    "    \n",
    "    for current_time in real_time_date(current_time):\n",
    "        for s, sensor in enumerate(sensors):\n",
    "            sensor_data[:,s] += sensor(data_seed[0, s], current_time)\n",
    "            sensor_data.popleft()\n",
    "            \n",
    "            data_seed[:,s] += np.random.randn(1)\n",
    "            data_seed.popleft()\n",
    "\n",
    "            noise = np.cumsum(np.random.randn(LOOKAHEAD))\n",
    "            ratio = np.max(np.abs(sensor_data[:,s])) / np.max(np.abs(noise))\n",
    "            \n",
    "            prediction = sensor_data[:,s] + NOISE_MAGNITUDE * noise * ratio\n",
    "            yield sensor_data[:,s], prediction\n",
    "\n",
    "\n",
    "for sensor_data, prediction in generate_data():\n",
    "    print(sensor_data, prediction)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mock-ME27tMT9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "373407d3eaf37c1f30cb933a82f2a6e12eb97f93c896c1a8bd249d0766482cd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
